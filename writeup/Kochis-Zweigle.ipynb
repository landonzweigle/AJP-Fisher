{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reinforcement Learning to Play a Fishing Game\n",
    "*By Keegan Kochis and Landon Zweigle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "---\n",
    "Ever since we have gotten into programming we have had a desire to do reinforcement learning, and this term project seemed like a perfect excuse to finally do it. When it came to deciding what to do RL on, we decided to use a [JavaFX](https://openjfx.io/) game Landon made a few years ago; a very simple fishing minigame where the goal is to put a bobber over a fish for a certain amount of time. This game had everything we were looking for; an evironment which is rather simple, but not too simple; and an easy way to communicate with it.\n",
    "\n",
    "Because the game was built in Java and our RL algorithm would be implemented in Python, we needed a way to communicate between Python and Java. For this we decided to use socket programming. Further, because of the random movement of the fish, we knew we had to use a neural network to approximate the Q-table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "---\n",
    "For our solution we of course needed a nueral network class. For this, we used some code provided to us in the course, a nueral network class and it's transitive optimizer class. We regularly visited lectures (lectures [17](https://nbviewer.jupyter.org/url/www.cs.colostate.edu/~cs445/notebooks/17%20Reinforcement%20Learning%20with%20Neural%20Network%20as%20Q%20Function.ipynb), [18](https://nbviewer.jupyter.org/url/www.cs.colostate.edu/~cs445/notebooks/18.1%20Reinforcement%20Learning%20to%20Control%20a%20Marble.ipynb)) for information regarding reinforcement learning algorithms, and a bit of code. Everything else was written by us.\n",
    "\n",
    "## Steps taken\n",
    "#### Java-Python Communications\n",
    "Because Landon wrote the game, he implemented the communication between Java and Python. There were several options he could have gone with but he ended up writting a simple java socket server which python would recieve the games state from, and map actions to, all while keeping the game loop synced to the RL algorithm loops.\n",
    "\n",
    "\n",
    "#### Convenient RL Neural Network\n",
    "Keegan integrated the neural network class with a few modifications. He implemented a trivial `EpsilonGreedy` method which had access to the nueral networks `self` variable. He also implemented a template `getReinforcement` method which would be later greatly tuned to increase algorithm performance.\n",
    "\n",
    "\n",
    "#### Main loop\n",
    "Landon worked on the \"main loop\" of our program. The main loop deals with the main processes in the RL algorithm; getting the data for each trial, training the model, saving the results, etc..\n",
    "\n",
    "#### Secondary Code\n",
    "For this project to work properly a lot of secondary code was neccessary. Such functions that were neccesary include a way of easily creating a csv of experiments to be run, and a way of executing experiments. At this point in development, we both contributed to this code.\n",
    "\n",
    "## Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
